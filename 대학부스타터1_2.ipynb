{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xaEOwqTKOUgaoog-aK0NBhor4tiuxYUs",
      "authorship_tag": "ABX9TyOFNGlaASOiZh2qicJR3sQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyoungmin-park/univ-starter/blob/main/%EB%8C%80%ED%95%99%EB%B6%80%EC%8A%A4%ED%83%80%ED%84%B01_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ0bJcMmeWYd",
        "outputId": "b58c56e5-2b07-4815-fc83-03c4611f0bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "\n",
        "#구글 드라이브 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1. 데이터 경로 설정\n",
        "train_dir = '/content/drive/Othercomputers/내 노트북/010.연도별 패션 선호도 파악 및 추천 데이터/01-1.정식개방데이터/Training/01.원천데이터'  # 학습 데이터 폴더\n",
        "val_dir = '/content/drive/Othercomputers/내 노트북/010.연도별 패션 선호도 파악 및 추천 데이터/01-1.정식개방데이터/Validation/01.원천데이터'  # 검증 데이터 폴더\n",
        "\n",
        "# 2. 학습용 데이터 로드\n",
        "train_records = []\n",
        "for filename in os.listdir(train_dir):  # 학습 폴더 내 모든 파일에 대해\n",
        "    if filename.endswith('.jpg'):  # .jpg 파일만 사용\n",
        "        parts = filename.split('_')  # 파일명을 '_' 기준으로 나눔\n",
        "        if len(parts) == 5:  # 파일명이 5부분으로 구성되어 있으면\n",
        "            img_path = os.path.join(train_dir, filename)  # 전체 경로 구성\n",
        "            style = parts[3]  # 스타일 정보 추출\n",
        "            gender = parts[4].replace('.jpg', '')  # 성별 정보 추출 (확장자 제거)\n",
        "            label = f\"{gender}_{style}\"  # 라벨 생성 (ex: male_casual)\n",
        "            train_records.append((img_path, label))  # 경로와 라벨을 리스트에 추가\n",
        "\n",
        "# DataFrame으로 변환\n",
        "train_df = pd.DataFrame(train_records, columns=['img_path', 'label'])\n",
        "\n",
        "# 3. 검증용 데이터 로드 (학습과 동일 방식)\n",
        "val_records = []\n",
        "for filename in os.listdir(val_dir):\n",
        "    if filename.endswith('.jpg'):\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) == 5:\n",
        "            img_path = os.path.join(val_dir, filename)\n",
        "            style = parts[3]\n",
        "            gender = parts[4].replace('.jpg', '')\n",
        "            label = f\"{gender}_{style}\"\n",
        "            val_records.append((img_path, label))\n",
        "\n",
        "val_df = pd.DataFrame(val_records, columns=['img_path', 'label'])\n",
        "\n",
        "# 4. 라벨 인코딩 (훈련 데이터 기준으로 고정)\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label_idx'] = label_encoder.fit_transform(train_df['label'])  # 훈련 데이터 라벨을 정수로 인코딩\n",
        "val_df['label_idx'] = label_encoder.transform(val_df['label'])  # 검증 데이터도 같은 인코더로 변환\n",
        "\n",
        "# 5. 이미지 전처리 정의 (훈련/검증용 다르게 설정)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # 크기 조정\n",
        "    transforms.RandomResizedCrop(224),  # 무작위 크롭\n",
        "    transforms.RandomHorizontalFlip(),  # 좌우 반전\n",
        "    transforms.ColorJitter(),  # 색상 변화\n",
        "    transforms.ToTensor(),  # 텐서로 변환\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # 정규화\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기 고정\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 6. PyTorch Dataset 클래스 정의\n",
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform):\n",
        "        self.df = dataframe.reset_index(drop=True)  # 인덱스 리셋\n",
        "        self.transform = transform  # 변환 저장\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)  # 데이터 수 반환\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.loc[idx, 'img_path']  # 경로 가져오기\n",
        "        label = self.df.loc[idx, 'label_idx']  # 라벨 인덱스 가져오기\n",
        "        image = Image.open(img_path).convert('RGB')  # 이미지 열기 및 RGB로 변환\n",
        "        image = self.transform(image)  # 변환 적용\n",
        "        return image, label  # 이미지와 라벨 반환\n",
        "\n",
        "# 7. DataLoader 생성\n",
        "train_dataset = FashionDataset(train_df, train_transforms)  # 학습용 데이터셋 생성\n",
        "val_dataset = FashionDataset(val_df, val_transforms)  # 검증용 데이터셋 생성\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # 학습용 로더\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # 검증용 로더\n",
        "\n",
        "# 8. ResNet-18 모델 정의 (사전학습 없이 무작위 초기화)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # GPU 사용 가능 여부 확인\n",
        "\n",
        "model = models.resnet18(weights=None)  # 사전학습 없이 랜덤 초기화\n",
        "model.fc = nn.Linear(model.fc.in_features, len(label_encoder.classes_))  # 출력층을 라벨 수에 맞게 수정\n",
        "model = model.to(device)  # 모델을 디바이스로 이동\n",
        "\n",
        "# 9. 손실 함수 및 최적화 기법 정의\n",
        "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류용 손실 함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저 사용\n",
        "\n",
        "# 10. 학습 루프\n",
        "for epoch in range(5):  # 총 5 에폭 동안 학습\n",
        "    model.train()  # 학습 모드\n",
        "    total_loss = 0  # 에폭별 손실 초기화\n",
        "    for images, labels in train_loader:  # 미니배치 반복\n",
        "        images, labels = images.to(device), labels.to(device)  # 디바이스로 이동\n",
        "        optimizer.zero_grad()  # 기울기 초기화\n",
        "        outputs = model(images)  # 예측값 출력\n",
        "        loss = criterion(outputs, labels)  # 손실 계산\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 파라미터 업데이트\n",
        "        total_loss += loss.item()  # 손실 누적\n",
        "    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss:.4f}\")  # 에폭별 손실 출력\n",
        "\n",
        "# 11. 검증 정확도 평가\n",
        "model.eval()  # 평가 모드 전환\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # 그래디언트 비활성화\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # 예측 라벨 추출\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # 정답 개수 누적\n",
        "\n",
        "accuracy = correct / total * 100  # 정확도 계산\n",
        "print(f\"✅ Validation Accuracy: {accuracy:.2f}%\")  # 정확도 출력"
      ]
    }
  ]
}